{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 불러오기\n",
    "csv_dir = \"./target_csv/\"\n",
    "csv_name = \"train_data_smi\"\n",
    "df = pd.read_csv(csv_dir + csv_name + '.csv')\n",
    "\n",
    "con_dir = \"./target_csv/\"\n",
    "con_name = \"target_protein_wiki\"\n",
    "con = pd.read_csv(con_dir + con_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wiki 컬럼에서 값이 \"FALSE\"인 행들을 필터링하여 Target Name 컬럼 값을 리스트로 저장합니다.\n",
    "false_list = con[con['Wiki'] == \"FALSE\"]['Target Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false_list에 있는 Target Name 값들을 df에서 제거합니다.\n",
    "df_filtered = df[~df['Target Name'].isin(false_list)]\n",
    "\n",
    "# 필터링된 데이터프레임을 저장하거나 출력합니다.\n",
    "df_filtered.to_csv(csv_dir + 'Filtered_' + csv_name + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df shape: (1952, 7)\n",
      "Filtered df shape: (1952, 7)\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 (필요할 경우)\n",
    "print(f\"Original df shape: {df.shape}\")\n",
    "print(f\"Filtered df shape: {df_filtered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1952"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: Target Name, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# 중복된 Smiles 값들을 찾아서 그 수를 계산합니다.\n",
    "duplicate_smiles_counts = df_filtered.groupby('Smiles')['Target Name'].nunique()\n",
    "\n",
    "# 중복된 Smiles 값들만 필터링합니다.\n",
    "duplicate_smiles = duplicate_smiles_counts[duplicate_smiles_counts > 1]\n",
    "\n",
    "# 결과 출력 (필요할 경우)\n",
    "print(duplicate_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate Smiles: 0\n"
     ]
    }
   ],
   "source": [
    "# 중복된 Smiles 값들을 찾아서 그 수를 계산합니다.\n",
    "duplicate_smiles_counts = df_filtered.groupby('Smiles')['Target Name'].nunique()\n",
    "\n",
    "# 중복된 Smiles 값들만 필터링합니다.\n",
    "duplicate_smiles = duplicate_smiles_counts[duplicate_smiles_counts > 1]\n",
    "\n",
    "# 중복된 Smiles 값의 수를 출력합니다.\n",
    "print(f\"Number of duplicate Smiles: {len(duplicate_smiles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 7)\n"
     ]
    }
   ],
   "source": [
    "# 중복된 Smiles 값을 가진 행들을 추출합니다.\n",
    "duplicate_smiles = df_filtered[df_filtered.duplicated('Smiles', keep=False)]\n",
    "\n",
    "# 중복된 Smiles 값을 기준으로 그룹화하고, 각 그룹에 속하는 Target Name들을 리스트로 묶어 출력합니다.\n",
    "grouped_duplicates = duplicate_smiles.groupby('Smiles')['Target Name'].apply(lambda x: list(x)).reset_index()\n",
    "\n",
    "# 결과 출력\n",
    "for index, row in grouped_duplicates.iterrows():\n",
    "    print(f\"Smiles: {row['Smiles']}\")\n",
    "    print(f\"Target Names: {row['Target Name']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(duplicate_smiles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "grouped_duplicates.to_csv(csv_dir + \"_duplicates\" + csv_name +\".csv\", index=False)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
